# gocrawler

A recursive, mirroring web crawler implemented.

The crawler should be a command-line tool that accepts a starting URL and a destination directory. The crawler will then download the page at the URL, save it in the destination directory, and then recursively proceed to any valid links in this page.

Features that are missing are Unit Tests due lack available test urls
